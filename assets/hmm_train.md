Below, you can plan around with parameters of the HMM-GMM training. The main parameters are the number of iterations and the number of components of each GMM. We suppose by default that each GMM has 5 states, and initialize the transition probabilities using a parallel-left-to-right model. Using pre-processed training data (MFCCs already extracted), an HMM is fitted for each label (0 to 9), and saved using Pickle (the same mode is then re-used above for the digit recognition). We finally evaluate the models on the pre-processed test sample, and display the accuracy. The accuracy is quite low, but should be compared to a random guess (10%). The method is clearly not state-of-the-art, and there is a wide variation in the training data, all of which drive the ASR accuracy down.